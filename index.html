<!doctype html>
<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="K. Erdem, P. Mazurek, P. Rarus">

    <title>XAI</title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/sky.css" id="theme">

    <!-- Theme used for syntax highlighting of code -->
    <!--    <link rel="stylesheet" href="css/highlight/isbl-editor-light.css">-->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">

</head>
<body>
<div class="reveal">
    <div class="slides">
        <section>
            <h2>Explainable AI</h2>
            <small>Kemal Erdem, Piotr Mazurek, Piotr Rarus</small>
        </section>

        <section>
            <h2>Agenda</h2>
            <ul>
                <li>XAI Introduction</li>
                <li>LIME</li>
                <li>GradCAM</li>
                <li>Integrated Gradients</li>
                <li>Potential issues with XAI methods</li>
            </ul>
        </section>

        <section>
            <h2>XAI Approaches</h2>
            <ul>
                <li>Attribution methods</li>
                <li>...</li>
            </ul>
        </section>


        <section>
            <h2>Integrated Gradients (IG)</h2>
            \begin{equation}
            IG_{i}(x)::=\left(x_{i}-x_{i}^{\prime}\right) \times \int_{\alpha=0}^{1} \frac{\partial
            F\left(x^{\prime}+\alpha \times\left(x-x^{\prime}\right)\right)}{\partial x_{i}} d \alpha
            \end{equation}
        </section>

        <section data-background-iframe="https://arxiv.org/pdf/1703.01365.pdf"
                 data-background-interactive>
        </section>


        <section>
            <h2>Visualisation</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_visualisation.png"></a>
        </section>

        <section>
            <h2>Engineering Approach</h2>
            <h4>Use IG implementation from Captum</h4>
        </section>

        <section data-background-iframe="https://captum.ai/api/integrated_gradients/"
                 data-background-interactive>
        </section>


        <section>
            <h2>How to use it?</h2>
            <h4>Load your data</h4>
            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
transform = transforms.Compose([
 transforms.Resize(224),
 transforms.ToTensor(),
 transforms.Normalize()
])

img = Image.open('image/for/which/I/need/prediction.jpg')

input = transform(img).unsqueeze(0)

input.size()
>> torch.Size(1, 3, 224, 224)
					</code></pre>

            <small>Inspired by the <a href="">official Captum tutorial</a></small>
        </section>

        <section>
            <h2>How to use it?</h2>

            <h4>Load the trained model</h4>
            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
model = models.resnet18(pretrained=True)
model = model.eval()
            </code></pre>

            <h4>Get the prediction</h4>
            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
output = F.softmax(model(input), dim=1)
output.size()
>> torch.Size(1, 1000)
            </code></pre>

            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
prediction_score, pred_label_idx = torch.topk(output, 1)
pred_label_idx.squeeze_()
>> 21
            </code></pre>

        </section>

        <section>
            <h2>How to use it?</h2>
            <h4>Use your model as an input to the Captum Object</h4>

            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
from captum.attr import IntegratedGradients

integrated_gradients = IntegratedGradients(model)

attributions_ig = integrated_gradients.attribute(input,
                                    target=pred_label_idx,
                                    n_steps=200)
attributions_ig.size()
>> torch.Size([1, 3, 224, 224])

        </code></pre>
        </section>

        <section>
            <h2>Enjoy the out-of-the-box model explainability</h2>
            <a href="https://captum.ai/tutorials/Resnet_TorchVision_Interpret"><img
                    src="assets/integrated_gradinets_resnet.png" width="80%"></a>

        </section>

        <section>
            <h2>Ok, it works for images, but can we do better?</h2>
            <h4 class="fragment">Actually yes</h4>
            <h4 class="fragment">IG is compatible with wide range of DL models</h4>
        </section>

        <section>
            <h2>NLP example</h2>
            <h4>Analyzing BERT</h4>

            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
from transformers import BertTokenizer, BertForQuestionAnswering

model = BertForQuestionAnswering.from_pretrained(model_path)

tokenized_question = BertTokenizer("What's up")
tensor_answer = model(tokenized_question)

integrated_gradients = IntegratedGradients(model)

attributions_ig = integrated_gradients.attribute(tokenized_question,
                    target=tensor_answer,
                    n_steps=200)
</code></pre>
            <small>More <a href="https://captum.ai/tutorials/Bert_SQUAD_Interpret">here</a></small>

        </section>

        <section>
            <h2>Visual question answering</h2>

            <a href="https://captum.ai/tutorials/Multimodal_VQA_Interpret"><img src="assets/vqa.png" width="50%"></a>
        </section>


        <section>
            <h2>API is great, but how does it actually work?</h2>
            <h4 class="fragment">To answer that we need to </h4>
        </section>

        <section>
            <h2>Baseline</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_baseline.png"></a>
            <blockquote>"Baseline input is meant to represent “absence” of feature input"</blockquote>

        </section>

        <section>
            <h2>Path intuition</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_path_example.png"></a>
        </section>

        <section>
            <h2>Quick recap - what is a gradient?</h2>
            \begin{equation}
            \frac{\partial F(x)}{\partial x}
            \end{equation}

            <blockquote>"How F(x) changes is we change x"</blockquote>
        </section>

        <section>
            <h2>Gradients in path</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_basic_intuition.png"></a>
        </section>

        <section>
            <h2>How can we "integrate" gradients?</h2>

            \begin{equation}
            IG_{i}(x)=\left(x_{i}-x_{i}^{\prime}\right) \times \int_{\alpha=0}^{1} \frac{\partial
            F\left(x^{\prime}+\alpha \times\left(x-x^{\prime}\right)\right)}{\partial x_{i}} d \alpha
            \end{equation}

            Where:<br>
            $i=$ feature<br>
            $x=$ input<br>
            $x^{\prime}=$ baseline<br>
            $\alpha=$ interpolation constant to perturbe features by
        </section>


        <section>
            <h2>Integral approximation</h2>

            \begin{equation}
            IG^{a}_{i}(x)=(x_{i}-x'_{i})\times\sum_{k=1}^{m}\frac{\partial F(x' + \frac{k}{m}\times(x - x'))}{\partial
            x_{i}} \times \frac{1}{m}
            \end{equation}

            Where:<br>
            $i=$ feature, $x=$ input, $x^{\prime}=$ baseline<br>
            $k=$ scaled feature perturbation constant<br>
            $m=$ number of steps in the Riemann sum approximation of the integral

        </section>

        <section>
            <h2>Still don't get it?</h2>
            <h4>Little visualisation</h4>
        </section>

        <section data-background-iframe="https://distill.pub/2020/attribution-baselines/">
        </section>

        <section>
            <h2>Can we code it?</h2>

            \begin{equation}
            IG^{a}_{i}(x)=(x_{i}-x'_{i})\times\sum_{k=1}^{m}\frac{\partial F(x' + \frac{k}{m}\times(x - x'))}{\partial
            x_{i}} \times \frac{1}{m}
            \end{equation}

            <h4>Yes we can</h4>
            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
baseline = torch.zeros_like(input)

input.requires_grad = True

steps=50

scaled_inputs = [baseline + (i / steps) * (input - baseline)
                for i in range(0, steps)]

</code></pre>
        </section>

        <section>
            <h2>Calculate gradients</h2>

            \begin{equation}
            IG^{a}_{i}(x)=(x_{i}-x'_{i})\times\sum_{k=1}^{m}\frac{\partial F(x' + \frac{k}{m}\times(x - x'))}{\partial
            x_{i}} \times \frac{1}{m}
            \end{equation}

            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
gradients = []
for scaled_input in scaled_inputs:
    output = F.softmax(model(scaled_input), dim=1)
    output = output.gather(1, pred_label_idx)

    model.zero_grad()
    output.backward()

    gradient = input.grad.detach().cpu().numpy()[0]
    gradients.append(gradient)

</code></pre>
        </section>


<section>
            <h2>Sum gradients</h2>

            \begin{equation}
            IG^{a}_{i}(x)=(x_{i}-x'_{i})\times\sum_{k=1}^{m}\frac{\partial F(x' + \frac{k}{m}\times(x - x'))}{\partial
            x_{i}} \times \frac{1}{m}
            \end{equation}

            <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="">
avg_grads = np.average(gradients, axis=0)
integrated_grad = (input - baseline) * avg_grads

</code></pre>
        </section>

        <section>
            <h2>How does it look in practice?</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_path_example.png"></a>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_proba_plot.png" width="50%"></a>
        </section>

        <section>
            <h2>Attribution visualisation</h2>
            <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"><img
                    src="assets/ig_visualisation.png" width="40%"></a>
        </section>

        <section>
            <h2>Open questions:</h2>
            <h4>How to choose a good baseline</h4>
            <h4> Do we need to bother with adding "zero" gradients?</h4>
        </section>

        <section data-background-iframe="https://distill.pub/2020/attribution-baselines/">
        </section>

        <section>
            <h2>XAI challenges</h2>
            <h4>How to evaluate explanation?</h4>
        </section>

        <section>
            <h2>XAI challenges</h2>
            <h4>Explaining wrong predictions</h4>
        </section>

        <section>
            <h2>XAI challenges</h2>
            <h4>Explanation don't have any sense, whatsoever</h4>
        </section>

        <section>
            <h2>Thanks</h2>
            <blockquote>"There's no such thing as a stupid question!"</blockquote>
            <p>
                <small>Kemal Erdem, Piotr Mazurek, Piotr Rarus</small><br/>
                <small>Presentation avalibe at: <a href="">Links</a></small><br/>
            </p>
        </section>
    </div>
</div>


<script src="dist/reveal.js"></script>
<script src="plugin/notes/notes.js"></script>
<script src="plugin/markdown/markdown.js"></script>
<script src="plugin/highlight/highlight.js"></script>
<script src="plugin/math/math.js"></script>
<script>
    // More info about config & dependencies:
    // - https://github.com/hakimel/reveal.js#configuration
    // - https://github.com/hakimel/reveal.js#dependencies
    Reveal.initialize({
        hash: true,
        controls: true,
        progress: true,
        slideNumber: true,
        overview: true,
        center: true,
        navigationMode: 'default',
        fragmentInURL: false,
        embedded: false,
        preloadIframes: null,
        autoSlide: 0,
        autoSlideStoppable: true,
        defaultTiming: 120,
        mouseWheel: false,
        previewLinks: false,
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        transitionSpeed: 'fast', // default/fast/slow
        backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom
        display: 'block',
        math: {
            mathjax: 'plugin/math/MathJax.js',
            config: 'TeX-AMS_HTML-full', // See http://docs.mathjax.org/en/latest/config-files.html
            // pass other options into `MathJax.Hub.Config()`
            TeX: {Macros: {RR: "{\\bf R}"}}
        },
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
    });
</script>
</body>
</html>
